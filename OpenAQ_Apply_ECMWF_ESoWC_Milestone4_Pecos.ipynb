{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jsonlines'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c9581822e10b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mjsonlines\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mndjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jsonlines'"
     ]
    }
   ],
   "source": [
    "\n",
    "import jsonlines\n",
    "import ndjson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pecos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Import the libriaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Anaconda or other python manager to install the above libraries. On anaconda use cmd: conda install ....python package .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Set the array variables for OpenAQ dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Import the OpenAQ Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 It uses the OpenAQ Dataset of a day in 2018 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 The default use OpenAQ_1.ndjson (a newline delimited format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Choose another one of the OpenAQ datasets in ndjson by changing the address of open('......')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with jsonlines.open('OpenAQ_1.ndjson') as reader:\n",
    "    for obj in reader:\n",
    "        #print(obj)\n",
    "        obj1 = pd.Series(obj)\n",
    "        #pd.read_csv(obj)\n",
    "        data.append(obj1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Import OpenAQ dataset to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dataset = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Define the ploting method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_df(df, x, y, title=\"\", xlabel='Date', ylabel='Value', dpi=100):\n",
    "    plt.figure(figsize=(16,5), dpi=dpi)\n",
    "    plt.plot(x, y, color='tab:red')\n",
    "    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Choose and print some variables from Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Dataset[['date','value','parameter','location']])\n",
    "\n",
    "print(Dataset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Split the 'date' variable to two variables because it has utc and local dates in one variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#How to split column into two columns\n",
    "#https://www.geeksforgeeks.org/split-a-text-column-into-two-columns-in-pandas-dataframe/\n",
    "\n",
    "Dataset[['Dateutc','Datelocal']] = Dataset.date.apply(lambda x: pd.Series(str(x).split(\",\")))\n",
    "\n",
    "Dataset_split = Dataset.Dateutc.apply(lambda x: pd.Series(str(x).split(\":\")))\n",
    "\n",
    "#print(Dataset_split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Convert new 'utc' (Date in utc) variable to date format for Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dataset['utc'] = pd.to_datetime(Dataset_split[1])\n",
    "\n",
    "#print(Dataset.dtypes)\n",
    "\n",
    "#print(Dataset)\n",
    "\n",
    "pd.to_datetime(Dataset['utc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Copy OpenAQ dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(Dataset2['utc'])\n",
    "#Dataset2.set_index('utc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Copy OpenAQ Dataset variable 'location' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Location_Subset = Dataset[['location']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 Sort descending and remove duplicate to get all unique station's 'location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Location_Subset.sort_values('location', ascending=False)\n",
    "\n",
    "Location_Subset = Location_Subset.drop_duplicates(subset='location', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 Set the OpenAQ dataset variable 'utc' (The date in utc) to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dataset2.index = Dataset2['utc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13 The setting the array variables results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test_results_location_subset = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "pm2 = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 The iteration over every station 'location' in the Location_Subset array "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15 Iterate over every AQ variable i.e. No2, So2, PM10, PM25 that the location has "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 It only iterates over the AQ variables that are measured at the choosen location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for LocationId in Location_Subset['location']:\n",
    " \n",
    "    print(LocationId)   \n",
    "  \n",
    "    Test_results_location_subset_parameter = []\n",
    "    \n",
    "    # 14 i Append the location being searched to array variable \n",
    "    \n",
    "    Test_results_location_subset_parameter.append(LocationId)\n",
    "    \n",
    "    # 14 ii Filter the OpenAQ Dataset for the location being searched for   \n",
    "    \n",
    "    Dataset3 = Dataset2[Dataset2['location']==LocationId]\n",
    "    \n",
    "    # 14 iii Format the utc variable to Date format of Pandas\n",
    "    \n",
    "    pd.to_datetime(Dataset3['utc'])\n",
    "    \n",
    "    #14 iv Copy all the AQ variables of searched for station\n",
    "    \n",
    "    Test_results_location_subset_parameter_subset = Dataset3[['parameter']].copy() \n",
    "         \n",
    "    #print(Test_results_location_subset_parameter_subset)\n",
    "    \n",
    "    #14 v Sort and remove duplicates getting unique AQ Variables\n",
    "    \n",
    "    Test_results_location_subset_parameter_subset.sort_values('parameter', ascending=False)\n",
    "    \n",
    "    Test_results_location_subset_parameter_subset = Test_results_location_subset_parameter_subset.drop_duplicates(subset='parameter', keep='first')\n",
    "\n",
    "    #15 Iterate over the AQ Variables \n",
    "    \n",
    "    for parameter in Test_results_location_subset_parameter_subset['parameter']:\n",
    "        \n",
    "        print(parameter)\n",
    "        \n",
    "        #15 i Append AQ variable to array\n",
    "        \n",
    "        Test_results_parameter = []\n",
    "        \n",
    "        Test_results_parameter.append(parameter)\n",
    "        \n",
    "        # 15 ii Filter the OpenAQ dataset for AQ Variable \n",
    "        \n",
    "        Dataset4 = Dataset3[Dataset3['parameter']==parameter]      \n",
    "\n",
    "        # 15 iv The get variable of Date from utc variable\n",
    "        \n",
    "        Dataset4['year'] = Dataset4['utc'].dt.year\n",
    "        \n",
    "        Dataset4['month'] = Dataset4['utc'].dt.month\n",
    "\n",
    "        Dataset4['day'] = Dataset4['utc'].dt.day\n",
    "        \n",
    "        pd.to_datetime(Dataset4['utc'])\n",
    "\n",
    "        Dataset5 = Dataset4;\n",
    "\n",
    "        #15 v The Pecos package to find errors in the OpenAQ dataset choosen on criteria\n",
    "        \n",
    "        # 15 v Initialize logger\n",
    "        pecos.logger.initialize()\n",
    "\n",
    "        # 15 v Create a Pecos PerformanceMonitoring data object\n",
    "        pm1 = pecos.monitoring.PerformanceMonitoring()\n",
    "        \n",
    "        pm1.add_dataframe(Dataset4)\n",
    "        \n",
    "        # 15 vi Check for missing values\n",
    "    \n",
    "        pm1.check_missing()\n",
    "        \n",
    "        # 15 vii Check for corrupt data values\n",
    "        \n",
    "        ###### Change value -999.00000 to other value that are not accepted \n",
    "        \n",
    "        pm1.check_corrupt([-999.000000],'value') \n",
    "\n",
    "# Add a composite signal which compares measurements to a model\n",
    "#wave_model = np.array(np.sin(10*clock_time/86400))\n",
    "#wave_measurments = pm.df[pm.trans['Wave']]\n",
    "#wave_error = np.abs(wave_measurments.subtract(wave_model,axis=0))\n",
    "#wave_error.columns=['Wave Error C', 'Wave Error D']\n",
    "#pm.add_dataframe(wave_error)\n",
    "#pm.add_translation_dictionary({'Wave Error': ['Wave Error C', 'Wave Error D']})\n",
    "\n",
    "        # 15 viii Check data for expected ranges\n",
    "        \n",
    "        #### CHOOSE criteria ### Change [0,10000000] to selected lower and high bound ###\n",
    "        \n",
    "        pm1.check_range([0, 10000000], 'value')\n",
    "\n",
    "        # 15 iix Check that the Date utc value is accurate i.e. expected measurements\n",
    "\n",
    "        pm1.check_range([2017, 2018], 'year')\n",
    "        pm1.check_corrupt([2,3,4,5,6,7,8,9,10,11],'month')\n",
    "        pm1.check_corrupt([2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30],'day')\n",
    "        \n",
    "        # 15 ix Append results to Array\n",
    "\n",
    "        print(pm1.test_results)\n",
    "        \n",
    "        Test_results_parameter.append(len(pm1.test_results))\n",
    "        \n",
    "        Test_results_parameter.append(pm1.test_results)\n",
    "        Test_results_parameter.append(Dataset5)\n",
    "        \n",
    "        Test_results_location_subset_parameter.append(Test_results_parameter)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #i = i + 1\n",
    "       \n",
    "\n",
    "    Test_results_location_subset.append(Test_results_location_subset_parameter)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16 Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Test_results_location_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17 Output results to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for Test_results_location in Test_results_location_subset:\n",
    "    \n",
    "    for Test_Parameter in Test_results_location[1:]:\n",
    "        \n",
    "        pecos.io.write_test_results(Test_Parameter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
